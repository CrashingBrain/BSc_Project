\label{ch:four}
\section{Mutual information}
    Mutual information can be used as a measure of correlation between random variables. 
	
	Mutual information is defined as
	\begin{equation}
		\I(X;Y) = \sum_{y\in\mathcal{Y}}\sum_{x\in\mathcal{X}} p(x,y) \log\left(\frac{p(x,y)}{p(x)p(y)}\right) 
	\end{equation}
	or equivalently, showing its relation to the entropies of the random variables
	\begin{equation}
		\I(X;Y) = \Ent(X) - \Ent(X\mid Y) = \Ent(X,Y) - \Ent(X\mid Y) - \Ent(Y\mid X)
	\end{equation}
	This relation can be seen more directly in Fig. \ref{fig:mutual_info}.\\
	Mutual information is nonnegative and bounded by the entropy of random variable $X$
	\begin{equation}
		0 \leq \I(X;Y) \leq \Ent(X)
	\end{equation}
	In this sense mutual information can also be interpreted as how much measuring one variable reduces the uncertainty of the other, thus being bounded by its uncertainty itself.
	
	\begin{figure}[h]
		\centering
		\input{images/mutual-info}
		\caption{Representation of mutual information $\I(X;Y)$ in relation with entropies $\Ent(X)$ and $\Ent(Y)$ and joint entropy $\Ent(X,Y)$ of the random variables .
		\label{fig:mutual_info}}
	\end{figure}	
\section{An eavesdropper that can choose the best channel to listen to}
    %[3]
   
    \begin{equation} \label{intrininfo}
    	\intrinfo{X}{Y}{Z}:= \inf_{Z\rightarrow \bar{Z}} \I(X;Y | \bar{Z})
    \end{equation}
\section{When correlation is unusable}
    % Here you can retake the examples of protocols in chapter 1. After explaining Maurer postulate, show that they don't violate Maurer because of reasons.
	\begin{quotation}
		Bound entanglement is a kind of correlation between Alice and Bob inaccessible to Eve but nevertheless of no use for generating a secret (quantum) key.\\
		Unfortunately the existence of such bound information, which would contradict the mentioned conjecture\footnotemark on the classical side of the picture, could not be proven so far.
	\end{quotation}
	\footnotetext{Shannon states that information theoretical security can be achieved only by parties sharing an unconditionally secret key initially. Maurer added also that this key can not be generated from scratch. Maurer+Wolf: \emph{Intrinsic information} between $A$ and $B$ given $E$ == \emph{secret key rate}(how much key can Alice and Bob generate from that $P_{ABE}$).}
		
