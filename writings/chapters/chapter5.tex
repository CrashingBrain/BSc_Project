The question of the existence of an analog to bound entanglement was firstly posed in \cite{GisWolf00} by Gisin and Wolf, where they analyzed the comparisons and correspondences between quantum and classical protocols for key agreement. 
The rise of bound information was a consequence of these correspondences.
Since then the topic was picked up by the scientific community of quantum cryptography and a couple more observation were made.\\
A probability distribution that presents bound information has not been found yet.
% Nevertheless 	a case for asymptotic bound information was proposed again by Wolf together with Renner \cite{RW03}.

\section{Tripartite Bound Information}
    A later work by Ac\'in et al. proposed the existence of bound information in a tripartite case \cite{ACM04}. 
    They analyzed the probability distribution resulting from measurement of a known bound entangled state. 
    Furthermore they also show that this distribution can be \textit{activated} the same way as in quantum entanglement.\\
    This result is different from what we want to achieve because the probability distribution is divided among parties Alice, Bob and Claire, with Eve being a fourth party in the distribution. 
    In fact, their result of bound information is valid only when considering \emph{pairs} of honest parties from the original distribution.
\section{The gaps between the bounds can be arbitrarily large}
    To distinguish and analyze the case of bound information some information theoretical measures are needed. 
    We already saw the secret key rate (section \ref{seckeyrate}) and the intrinsic information (section \ref{intrininfo}) and we already presented the question of bound information in terms of such measures. \\
    In \cite{RW03} a new measure of \emph{reduced intrinsic information} $\redintrinfo{X}{Y}{Z}$ is introduced as an upper bound on secret key rate, lower than just the normal intrinsic information.
    For every $P_{XYZ}$ it holds
    \begin{equation} \label{eq:bounds}
    	\keyrate{X}{Y}{Z} \leq \redintrinfo{X}{Y}{Z} \leq \intrinfo{X}{Y}{Z}
    \end{equation}
    	Reduced intrinsic information is a strictly stronger upper bound on secret key rate than intrinsic information.
    	More importantly, Renner and Wolf prove that the gap between reduced and normal intrinsic information can be arbitrarily large. 
    	Considering then that the former is an upper bound to secret key rate, and the latter is a lower bound to information of formation, this implies the existence of asymptotic bound information.
    	\begin{figure}
    		\input{images/bounds}
    		\caption{The different measures for $P_{XYZ}$ and how they bound each other.}
    	\end{figure}
    	
\section{A candidate probability distribution}
    Wolf and Renner proposed in \cite{RW03} for the first time a probability distribution (Fig. \ref{Tab:candidate}) which is a good candidate for the classical analogy of \emph{bound entanglement}. 
    In fact, they offer a probability distribution that asymptotically has bound information. 
    They also show, for such a distribution, that 
    \begin{equation}
    	\keyrate{X}{Y}{Z} \neq \intrinfo{X}{Y}{Z}
    \end{equation}  
     and they emphasize that this is the first time that equality does not hold.\\
     
	\begin{figure}[h!]
	\begin{center}
		\begin{tabular}{|l r||c|c|c|c|}
		    \hline 
		    		 &	$X$ & $0$ & $1$ & $2$ & $3$ \\ 
		    $Y$ &		  &		&			&			&		\\
		    \hline 
		    \hline
		    $0$ &		   & $1/8$ & $1/8$ & $0$ & $0$ \\ 
		    \hline 
		    $1$ &		   & $1/8$ & $1/8$ & $0$ & $0$ \\ 
		    \hline 
		    $2$ &		   & $0$ & $0$ & $1/4$ & $0$ \\ 
		    \hline 
		    $3$ &		   & $0$ & $0$ & $0$ & $1/4$ \\ 
		    \hline 
		  \end{tabular} 
	\end{center}		

%\begin{table}[pos]
%\centering
%\caption{My caption}
%\label{my-label}
%\begin{tabular}{|l|l|l|l|l|l|}
%\hline
%\multicolumn{2}{|r|}{$X$} & \multirow{2}{*}{0} & \multirow{2}{*}{1} & \multirow{2}{*}{2} & \multirow{2}{*}{3} \\
%\multicolumn{2}{|l|}{Y}   &                    &                    &                    &                    \\ \hline
%\multicolumn{2}{|l|}{0}   & 1/8                & 1/8                & 0                  & 0                  \\ \hline
%\multicolumn{2}{|l|}{1}   & 1/8                & 1/8                & 0                  & 0                  \\ \hline
%\multicolumn{2}{|l|}{2}   & 0                  & 0                  & 1/4                & 0                  \\ \hline
%\multicolumn{2}{|l|}{3}   & 0                  & 0                  & 0                  & 1/4                \\ \hline
%\end{tabular}
%\end{table}
		
	    $$Z \equiv X + Y\; (mod\: 2)\; \text{ if } X,Y \in \{ 0,1\}$$ 
	    $$Z \equiv X\; (mod\: 2)\; \text{ if } X \in \{ 2,3\}$$ 
	    $$U \equiv \lfloor X/2 \rfloor $$
	    \caption{Probability distribution proposed by Renner, Wolf and Skripsky in \cite{RW03} for which it holds that $\keyrate{X}{Y}{Z} \neq \intrinfo{X}{Y}{Z}$}
	    \label{Tab:candidate}
	\end{figure}	 
	
		For this probability distribution we have
	$$ \intrinfo{X}{Y}{Z} = 3/2 ,\; \keyrate{X}{Y}{Z} = 1 , \; \redintrinfo{X}{Y}{Z} = 1 $$
	More promising is another probability they offer at the end (Fig. \ref{Tab:candidate2}) which is a slight modification of the first.
	
	
	\begin{figure}
		\begin{center}
		\begin{tabular}{|l r||c|c|c|c|}
		    \hline 
		    		 &	$X$ & $0$ & $1$ & $2$ & $3$ \\ 
		    $Y$ &		  &		&			&			&		\\
		    \hline 
		    \hline
		    $0$ &		   & $1/8$ & $1/8$ & $a$ & $a$ \\ 
		    \hline 
		    $1$ &		   & $1/8$ & $1/8$ & $a$ & $a$ \\ 
		    \hline 
		    $2$ &		   & $a$ & $a$ & $1/4$ & $0$ \\ 
		    \hline 
		    $3$ &		   & $a$ & $a$ & $0$ & $1/4$ \\ 
		    \hline 
		  \end{tabular} 
	\end{center}
	
			$$Z \equiv X + Y\; (mod\: 2)\; \text{ if } X,Y \in \{ 0,1\}$$ 
	    	$$Z \equiv X\; (mod\: 2)\; \text{ if } X,Y \in \{ 2,3\}$$ 
	    	$$Z = (X,Y) \text{ otherwise} $$
	    	
	    	\caption{A candidate probability distribution for bound information, for $a\geq 0$ (and renormalized).}
	    	\label{Tab:candidate2}
	\end{figure}
    